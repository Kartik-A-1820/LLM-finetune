{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687df035-fe64-46f1-a4a4-4096d5ebdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d63056-c146-4248-9a3f-e70f3b765852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = \"EleutherAI/pythia-410m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1df56ce-6d1f-4d66-88b4-49a4fd89465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": [\n",
    "        # \"data/datascience_2000.jsonl\",\n",
    "        \"data/datascience_1000_multistep.jsonl\",\n",
    "        # \"data/datascience_1000_errors.jsonl\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7854b01d-e345-4988-b4d4-9af286e5a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "splits = raw_ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds, eval_ds = splits[\"train\"], splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa76d2c-713b-4fd7-b4a3-e7fd2e9f7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c287552-b614-491a-a4e8-edb5205a35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(ex):\n",
    "    prompt = f\"### Instruction:\\n{ex['instruction']}\\n\\n### Response:\\n{ex['output']}\"\n",
    "    prompt += tokenizer.eos_token\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "train_ds = train_ds.map(format_example, remove_columns=train_ds.column_names)\n",
    "eval_ds  = eval_ds.map(format_example,  remove_columns=eval_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f6c7ee-bd68-4b19-ab62-4f6ec1841e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f544eb094c4b978ab4bba82fd0c827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "eval_tok  = eval_ds.map(tokenize_fn,  batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f00fea-6f2b-4b6e-8d61-cc105ffbf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6e6bdc-00a1-48f6-8245-e1e5db230820",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7905b9e-a28e-4bf1-a4e4-3a19c61be2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e163fbc1-f2ae-4395-a3b2-ea7be1e3ce51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 1024)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (query_key_value): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
       "          (dense): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
       "          (dense_4h_to_h): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "  )\n",
       "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b132807a-feb4-45fe-839b-9cdd94ca3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Filter df for rows where 'category' contains 'A', then encode 'city' with one-hot, and train/test split with 80-20%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4894c4-2ae8-43de-9cb6-edafbab82496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "D:\\Users\\KARTIK\\.conda\\envs\\torch\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:66: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter df for rows where 'category' contains 'A', then encode 'city' with one-hot, and train/test split with 80-20%.\n",
      "\n",
      "I am not sure if this is the best way to go about it.\n",
      "\n",
      "A:\n",
      "\n",
      "I think this is the best way to go about it.\n",
      "I am not sure if this is the best way to go about it.\n",
      "\n",
      "I think it is.  I would recommend using a one-hot encoding.  One-hot encoding is a way to encode a vector of one-hot values.  One-hot values are one-hot, but not necessarily one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-one.  One-to-one means that the value is one-to-\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(instruction, return_tensors=\"pt\").to(\"cuda\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=512, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7404dc5-b8b9-4adb-818c-7331e6978c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.gradient_checkpointing_enable()\n",
    "# model.enable_input_require_grads()\n",
    "# model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd4aa64b-f760-4367-8a08-39ef0b38ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414e041d-70d3-4c9d-ad83-df1edd5c0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609ff79e-d0e7-4737-95ca-766e75256021",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pythia-lora\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa3d6f19-0c3c-4b4d-bdd7-7ec9cd1b71e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360.82896\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint()/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3785adf3-4bb8-4f7e-9c81-1e90e7fa09d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KARTIK\\AppData\\Local\\Temp\\ipykernel_17540\\462725698.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=eval_tok,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0423a92b-9c63-46b8-a0b5-ad4a314d09d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 13:11:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.893900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.521900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.073800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.28791256388028463, metrics={'train_runtime': 47644.2927, 'train_samples_per_second': 0.189, 'train_steps_per_second': 0.003, 'total_flos': 9804233834496000.0, 'train_loss': 0.28791256388028463, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "587f9750-0f51-4c9f-84f8-bba5b2cab65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./pythia-lora-final\\\\tokenizer_config.json',\n",
       " './pythia-lora-final\\\\special_tokens_map.json',\n",
       " './pythia-lora-final\\\\tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./pythia-lora-final\")\n",
    "tokenizer.save_pretrained(\"./pythia-lora-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37814f69-a514-4a65-a0c9-126f4e68b55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINISHED'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"FINISHED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "548f4eff-4452-4d81-8f0a-56f1ee3026c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cc89682-1ab3-43f3-80ae-d65ac5f91e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Filter df for rows where 'category' contains 'A', then encode 'city' with one-hot, and train/test split with 80-20%.\n",
      "\n",
      "### Response:\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "df = df[df['category'].str.contains('A', na=False)]\n",
      "df_ohe = pd.get_dummies(df, columns=['city'])\n",
      "train, test = train_test_split(df_ohe, test_size=0.2, random_state=42)\n",
      "print(train.shape, test.shape)\n",
      "df_ohe.to_dict(orient='records')\n",
      "df_ohe.to_csv('test.csv', index=False)\n",
      "df_ohe.drop('city', 1)\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "\n",
      "### Response:\n",
      "df_ohe = df_ohe.to_dict(orient='records')\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "df_ohe.drop('city', 1)\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "\n",
      "### Response:\n",
      "df_ohe = df_ohe.to_dict(orient='records')\n",
      "df_ohe = pd.get_dummies(df_ohe, columns=['city'])\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "df_ohe.drop('city', 1)\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "\n",
      "### Response:\n",
      "df_ohe = df_ohe.to_dict(orient='records')\n",
      "df_ohe = pd.get_dummies(df_ohe, columns=['city'])\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "df_ohe.drop('city', 1)\n",
      "\n",
      "### Response:\n",
      "df_ohe = df_ohe.to_csv('city.csv', index=False)\n",
      "df_ohe = pd.get_dummies(df_ohe, columns=['city'])\n",
      "df_ohe.to_csv('city.csv', index=False)\n",
      "\n",
      "### Response:\n",
      "df_ohe = df_ohe.to_csv('city.csv', index=False)\n",
      "df_ohe = pd\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt_template, return_tensors=\"pt\").to(\"cuda\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=512, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6c26a-3e97-46d6-8d08-bed2539bd794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_kernel)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
